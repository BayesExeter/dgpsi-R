---
title: >
  DGP Emulation with the Heteroskedastic Gaussian Likelihood
output: rmarkdown::html_vignette
bibliography: references.bib 
description: >
  DGP emulation of the motorcycle accident data.
vignette: >
  %\VignetteIndexEntry{DGP Emulation with the Heteroskedastic Gaussian Likelihood}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  echo = TRUE,
  eval = FALSE
)
```

This vignette gives a demonstration of the package on emulating the popular motorcycle dataset [@silverman1985].

## Load packages and data

We start by loading packages:

```{r}
library(dgpsi)
library(MASS)
library(patchwork)
```

We now load the training data points,

```{r}
X <- mcycle$times
Y <- mcycle$accel
```

scale them,

```{r}
X <- (X - min(X))/(max(X)-min(X))
Y <- scale(Y, center = TRUE, scale = TRUE)
```

and plot them:

```{r}
plot(X, Y, pch = 16, cex = 1, xlab = 'Time', ylab = 'Acceleration', cex.axis = 1.3, cex.lab = 1.3)
```

![](images/motorcycle_data.png){width=90%}

Before constructing an emulator, we first specify a seed with `set_seed()` from the package for reproducibility

```{r}
set_seed(9999)
```

and split a training data set and a testing data set:

```{r}
test_idx <- sample(seq_len(length(X)), size = 20)
train_X <- X[-test_idx]
train_Y <- Y[-test_idx,]
test_x <- X[test_idx]
test_y <- Y[test_idx,]
```

## Construct and train a DGP emulator

We consider a three-layered DGP emulator with squared exponential kernels:

```{r}
m_dgp <- dgp(train_X, train_Y, depth = 3, likelihood = "Hetero")
```

```
## Auto-generating a 3-layered DGP structure ... done
## Initializing the DGP emulator ... done
## Training the DGP emulator: 
## Iteration 500: Layer 3: 100%|██████████| 500/500 [00:14<00:00, 35.52it/s]
## Imputing ... done
```

We choose a heteroskedastic Gaussian likelihood by setting `likelihood = "Hetero"` since the data drawn in the plot show varying noises. We can use `summary()` to visualize the structure and specifications for the trained DGP emulator:

```{r}
summary(m_dgp)
```

<iframe src="https://github.com/mingdeyu/dgpsi-R/blob/master/vignettes/images/motor_dgp.html" width="100%" height="400" style="border: none;"></iframe>

For comparison, we also build a GP emulator (by `gp()`) that incorporates homogeneous noises by setting `nugget_est = T` and the initial nugget value to $0.01$:

```{r}
m_gp <- gp(train_X, train_Y, nugget_est = T, nugget = 1e-2) 
```

```
## Auto-generating a GP structure ... done
## Initializing the GP emulator ... done
## Training the GP emulator ... done
```

We can also summarize the trained GP emulator by `summary()`:

```{r}
summary(m_gp)
```

<iframe src="https://github.com/mingdeyu/dgpsi-R/blob/master/vignettes/images/motor_gp.html" width="100%" height="400" style="border: none;"></iframe>

## Validation

We are now ready to validate both emulators via `validate()` at 20 out-of-sample testing positions generated earlier:

```{r}
m_dgp <- validate(m_dgp, test_x, test_y)
```

```
## Initializing the OOS ... done
## Calculating the OOS ... done
## Saving results to the slot 'oos' in the dgp object ... done
```

```{r}
m_gp <- validate(m_gp, test_x, test_y)
```

```
## Initializing the OOS ... done
## Calculating the OOS ... done
## Saving results to the slot 'oos' in the gp object ... done
```

Note that using `validate()` before plotting can saving computations involved in `plot()` because `validate()` stores validation results in the emulator objects. Finally, we plot the OOS validations for the GP emulator:

```{r}
plot(m_gp, test_x, test_y)
```

```
## Validating and computing ... done
## Post-processing OOS results ... done
## Plotting ... done
```

![](images/motorcycle_gp_oos.png){width=90%}

and for the DGP emulator:

```{r}
plot(m_dgp, test_x, test_y)
```

```
## Validating and computing ... done
## Post-processing OOS results ... done
## Plotting ... done
```

![](images/motorcycle_dgp_oos.png){width=90%}

Note that we still need to provide `test_x` and `test_y` to `plot()` even they have already been provided to `validate()`. Otherwise, `plot()` will draw the LOO cross validation plot. The visualizations above show that the DGP emulator gives a better performance than the GP emulator on modeling the heteroskedastic noises embedded in the underlying data set, even though they have quite similar NRMSEs.

### References

